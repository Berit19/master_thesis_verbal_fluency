{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# import custom-made functions\n",
    "from utils.textgrid_export import export_transcript_as_textgrid\n",
    "\n",
    "\n",
    "input_folder = \"../online/Audiofiles/\" # this folder contains wav or mp4 files to be transcribed\n",
    "output_folder = \"../output/\" # whisper output txt files and TextGrid files will be saved here in the \"tsv\" and \"textgrid\" folders, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the whisper model\n",
    "# set the device, batch size, and compute type\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # setting device on GPU if available, else CPU\n",
    "batch_size = 16 if device == \"cuda\" else 4 # reduce to 4 if low on GPU memory\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"default\"\n",
    "model_size = \"large-v3\" \n",
    "print(f\"* Using device: {device} \\n* Batch size: {batch_size} \\n* Model size: {model_size} \\n* Compute type: {compute_type}\")\n",
    "\n",
    "# load model from whisper\n",
    "model = whisperx.load_model(model_size, device, compute_type=compute_type, language='nl')\n",
    "\n",
    "\n",
    "### Transcribe all audio/video files in the input folder\n",
    "# iterate over files in the videos folder & apply whisper model on each videos\n",
    "for filename in os.listdir(input_folder):\n",
    "    path = os.path.join(input_folder, filename)\n",
    "\n",
    "    # check if it is a wav file\n",
    "    if filename.endswith(\".wav\") or filename.endswith(\".mp4\"):\n",
    "        # check if the output file already exists\n",
    "        output_filename = filename.split(\".\")[0] + \".txt\"\n",
    "        if os.path.exists(os.path.join(output_folder, \"tsv\", output_filename)):\n",
    "            print(f\"{output_filename} already exists in the output folder\")\n",
    "        else:\n",
    "            #apply whisper model on each file\n",
    "            \n",
    "            # 1. Transcribe with original whisper (batched)\n",
    "            try:\n",
    "                audio = whisperx.load_audio(path)\n",
    "            except:\n",
    "                print(\"The audio files is not working:\" + filename)\n",
    "            else:\n",
    "                result = model.transcribe(audio, batch_size=batch_size)\n",
    "\n",
    "                # 2. Align whisper output\n",
    "                model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "                result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "\n",
    "                transcribed_words = list()\n",
    "\n",
    "                # make sure punctuation is removed and everything is lowercase\n",
    "                for i in result['word_segments']:\n",
    "                    # remove punctuation\n",
    "                    word = re.sub(r'[^\\w\\s]', '',i[\"word\"] )\n",
    "                    # make lowercase\n",
    "                    word = word.lower()\n",
    "                    i[\"word\"] = word\n",
    "                    transcribed_words.append(word)\n",
    "\n",
    "                # tsv/txt output\n",
    "                with open(output_filename, 'w', newline='') as f_output:\n",
    "                    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "                    tsv_output.writerow(transcribed_words) \n",
    "                \n",
    "                # textgrid output\n",
    "                if len(transcribed_words) > 0:\n",
    "                    export_transcript_as_textgrid(result, output_filename, output_folder)\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
